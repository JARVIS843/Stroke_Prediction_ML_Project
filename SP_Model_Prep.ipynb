{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540ffbb8",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6d6ae",
   "metadata": {},
   "source": [
    "We begin by loading the original healthcare stroke dataset, which is located in the Dataset folder. We'll use pandas to read it into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df62c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = 'Dataset/healthcare-dataset-stroke-data.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display basic information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91068b0d",
   "metadata": {},
   "source": [
    "We will take exactly 100 rows, preserving the proportion of stroke == 1 and stroke == 0 from the original dataset. The output will be saved to the Dataset/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b978ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke\n",
       "0    0.95\n",
       "1    0.05\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get stratified sample of exactly 100 rows\n",
    "# First, split out 100 samples using stratified sampling on the 'stroke' column\n",
    "_, sample_df = train_test_split(\n",
    "    df,\n",
    "    stratify=df['stroke'],\n",
    "    test_size=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Verify the distribution\n",
    "sample_df['stroke'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d8f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive stroke cases in sample: 5\n"
     ]
    }
   ],
   "source": [
    "# Count how many samples have stroke == 1\n",
    "stroke_positive_count = sample_df['stroke'].sum()\n",
    "print(f\"Number of positive stroke cases in sample: {stroke_positive_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45cfac",
   "metadata": {},
   "source": [
    "To make the sample dataset easier to trace, we will overwrite the id column so that it runs from 1 to 100 sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "180455d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  stroke\n",
       "379    1       0\n",
       "4847   2       0\n",
       "1834   3       0\n",
       "3341   4       0\n",
       "1265   5       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overwrite the 'id' column with values from 1 to 100\n",
    "sample_df = sample_df.copy()\n",
    "sample_df['id'] = range(1, 101)\n",
    "\n",
    "# Confirm the change\n",
    "sample_df[['id', 'stroke']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1d077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stratified 100-sample dataset saved to 'Dataset/SP_sample.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the sample to the Dataset folder\n",
    "sample_df.to_csv('Dataset/SP_sample.csv', index=False)\n",
    "print(\"✅ Stratified 100-sample dataset saved to 'Dataset/SP_sample.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fe43a",
   "metadata": {},
   "source": [
    "## Evaluate and Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b879cd4",
   "metadata": {},
   "source": [
    "Stroke Prediction produces a model, exported using tflite and onnx formats. The two formats would be evaluated and analyzed in terms of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c67170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad5663",
   "metadata": {},
   "source": [
    "Below is a preprocessing function that will be used to prepare the data for training and testing; it follows the same steps as the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b708830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample_data(df_sample):\n",
    "    df = df_sample.copy()\n",
    "    \n",
    "    df = df.drop(columns=\"id\")\n",
    "    \n",
    "    df[\"age_group\"] = df[\"age\"].apply(lambda x: \"Infant\" if (x >= 0) & (x <= 2)\n",
    "        else (\"Child\" if (x > 2) & (x <= 12)\n",
    "        else (\"Adolescent\" if (x > 12) & (x <= 18)\n",
    "        else (\"Young Adults\" if (x > 19) & (x <= 35)\n",
    "        else (\"Middle Aged Adults\" if (x > 35) & (x <= 60)\n",
    "        else \"Old Aged Adults\")))))\n",
    "\n",
    "    df['bmi'] = df['bmi'].fillna(df.groupby([\"gender\", \"ever_married\", \"age_group\"])[\"bmi\"].transform('mean'))\n",
    "    \n",
    "    df = df[(df[\"bmi\"] < 66) & (df[\"bmi\"] > 12)]\n",
    "    df = df[(df[\"avg_glucose_level\"] > 56) & (df[\"avg_glucose_level\"] < 250)]\n",
    "    df = df.drop(df[df[\"gender\"] == \"Other\"].index)\n",
    "    \n",
    "    had_stroke = df[df[\"stroke\"] == 1]\n",
    "    no_stroke = df[df[\"stroke\"] == 0]\n",
    "    upsampled_had_stroke = resample(had_stroke, replace=True, n_samples=no_stroke.shape[0], random_state=123)\n",
    "    upsampled_data = pd.concat([no_stroke, upsampled_had_stroke])\n",
    "    \n",
    "    # One-hot encoding\n",
    "    cols = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "    dums = pd.get_dummies(upsampled_data[cols], dtype=int)\n",
    "    \n",
    "    # Ensure all expected dummy columns are present\n",
    "    expected_dummy_cols = [\n",
    "        'gender_Female', 'gender_Male',\n",
    "        'ever_married_No', 'ever_married_Yes',\n",
    "        'work_type_Govt_job', 'work_type_Never_worked',\n",
    "        'work_type_Private', 'work_type_Self-employed', 'work_type_children',\n",
    "        'Residence_type_Rural', 'Residence_type_Urban',\n",
    "        'smoking_status_Unknown', 'smoking_status_formerly smoked',\n",
    "        'smoking_status_never smoked', 'smoking_status_smokes'\n",
    "    ]\n",
    "    \n",
    "    for col in expected_dummy_cols:\n",
    "        if col not in dums:\n",
    "            dums[col] = 0  # Add missing columns as 0s\n",
    "    \n",
    "    # Reorder to match model input\n",
    "    dums = dums[expected_dummy_cols]\n",
    "    \n",
    "    model_data = pd.concat([upsampled_data.drop(columns=cols), dums], axis=1)\n",
    "\n",
    "    # Encode ordinal column\n",
    "    encoder = LabelEncoder()\n",
    "    model_data[\"age_group\"] = encoder.fit_transform(model_data[\"age_group\"])\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in ['age', 'avg_glucose_level', 'bmi']:\n",
    "        scaler.fit(model_data[[col]])\n",
    "        model_data[col] = scaler.transform(model_data[[col]])\n",
    "        \n",
    "    return model_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314a1cf",
   "metadata": {},
   "source": [
    "Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee87e7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Rural</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645650</td>\n",
       "      <td>0.068632</td>\n",
       "      <td>0.497706</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364614</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>0.777523</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450147</td>\n",
       "      <td>0.192550</td>\n",
       "      <td>0.245413</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.718964</td>\n",
       "      <td>0.434299</td>\n",
       "      <td>0.341743</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169110</td>\n",
       "      <td>0.348132</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  avg_glucose_level       bmi  stroke  age_group  gender_Female  \\\n",
       "0  0.645650           0.068632  0.497706       0          3              1   \n",
       "1  0.364614           0.158876  0.777523       0          5              1   \n",
       "2  0.450147           0.192550  0.245413       0          3              0   \n",
       "3  0.718964           0.434299  0.341743       0          3              1   \n",
       "4  0.169110           0.348132  0.247706       0          0              1   \n",
       "\n",
       "   gender_Male  ever_married_No  ever_married_Yes  work_type_Govt_job  \\\n",
       "0            0                0                 1                   0   \n",
       "1            0                0                 1                   0   \n",
       "2            1                1                 0                   0   \n",
       "3            0                0                 1                   0   \n",
       "4            0                1                 0                   0   \n",
       "\n",
       "   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
       "0                       0                  1                        0   \n",
       "1                       0                  1                        0   \n",
       "2                       0                  1                        0   \n",
       "3                       0                  1                        0   \n",
       "4                       0                  1                        0   \n",
       "\n",
       "   work_type_children  Residence_type_Rural  Residence_type_Urban  \\\n",
       "0                   0                     1                     0   \n",
       "1                   0                     0                     1   \n",
       "2                   0                     0                     1   \n",
       "3                   0                     1                     0   \n",
       "4                   0                     1                     0   \n",
       "\n",
       "   smoking_status_Unknown  smoking_status_formerly smoked  \\\n",
       "0                       0                               1   \n",
       "1                       0                               0   \n",
       "2                       0                               0   \n",
       "3                       1                               0   \n",
       "4                       1                               0   \n",
       "\n",
       "   smoking_status_never smoked  smoking_status_smokes  \n",
       "0                            0                      0  \n",
       "1                            1                      0  \n",
       "2                            0                      1  \n",
       "3                            0                      0  \n",
       "4                            0                      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw dataset\n",
    "df_raw = pd.read_csv(\"Dataset/SP_sample.csv\")\n",
    "\n",
    "model_data = preprocess_sample_data(df_raw)\n",
    "\n",
    "X_processed = model_data.drop(columns=\"stroke\")\n",
    "y_true = model_data[\"stroke\"]\n",
    "\n",
    "model_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665620a",
   "metadata": {},
   "source": [
    "Run TFLite Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc5805a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"Models/best_model_91.onnx\"\n",
    "session = ort.InferenceSession(onnx_path)\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "X_input = np.array(X_processed, dtype=np.float32)\n",
    "onnx_preds = session.run(None, {input_name: X_input})[0].flatten()\n",
    "y_pred_onnx = (onnx_preds > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d401f4c",
   "metadata": {},
   "source": [
    "Below is the function definition for evaluating the ONNX model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e026f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, label):\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3cfbd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ONNX Model ---\n",
      "Accuracy:  0.9211\n",
      "Precision: 0.8636\n",
      "Recall:    1.0000\n",
      "F1 Score:  0.9268\n",
      "Confusion Matrix:\n",
      "[[80 15]\n",
      " [ 0 95]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_true, y_pred_onnx, \"ONNX Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404316a",
   "metadata": {},
   "source": [
    "Below is a comparison between the performance of the orignial model and the onnx model (TL;DR: They're practically the same):\n",
    "\n",
    "| **Metric**             | **Original Model (Full Test Set)** | **ONNX Model (Sample Dataset)** | **Remarks**                                |\n",
    "|------------------------|-------------------------------------|----------------------------------|--------------------------------------------|\n",
    "| **Accuracy**           | 91.04%                              | 92.11%                           | Very close; ONNX model slightly higher.    |\n",
    "| **Precision (Stroke)** | 85%                                 | 86.36%                           | Slight improvement in sample run.          |\n",
    "| **Recall (Stroke)**    | 100%                                | 100%                             | Perfect in both – no false negatives.      |\n",
    "| **F1 Score (Stroke)**  | 92%                                 | 92.68%                           | Slight boost on the embedded test.         |\n",
    "| **False Positives**    | 169                                 | 15                               | Consistent ratio; no impact on safety.     |\n",
    "| **False Negatives**    | 0                                   | 0                                | Critical metric maintained.              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fa546",
   "metadata": {},
   "source": [
    "## Convert to RKNN Model to be deployed on Embedded Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996dd693",
   "metadata": {},
   "outputs": [
    {
     "ename": "ContextualVersionConflict",
     "evalue": "(torch 2.5.1 (/home/jarvis/.local/lib/python3.10/site-packages), Requirement.parse('torch<=2.1.0,>=1.13.1'), {'rknn-toolkit2'})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ONNX_MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Models/best_model_91.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m RKNN_MODEL_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Models/best_model_91.rknn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m rknn \u001b[38;5;241m=\u001b[39m \u001b[43mRKNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--> Configuring RKNN (FP16)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m rknn\u001b[38;5;241m.\u001b[39mconfig(\n\u001b[1;32m     12\u001b[0m     mean_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     std_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     target_platform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrk3588\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     quantized_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/StrokePredictionML/lib/python3.10/site-packages/rknn/api/rknn.py:51\u001b[0m, in \u001b[0;36mRKNN.__init__\u001b[0;34m(self, verbose, verbose_file)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose_file:\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrknn_log\u001b[38;5;241m.\u001b[39md(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSave log info to: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(verbose_file))\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrknn_base \u001b[38;5;241m=\u001b[39m \u001b[43mRKNNBase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mrknn/api/rknn_base.py:79\u001b[0m, in \u001b[0;36mrknn.api.rknn_base.RKNNBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/StrokePredictionML/lib/python3.10/site-packages/pkg_resources/__init__.py:534\u001b[0m, in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    532\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Requirement\u001b[38;5;241m.\u001b[39mparse(dist)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Requirement):\n\u001b[0;32m--> 534\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mget_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dist, Distribution):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected str, Requirement, or Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m, dist)\n",
      "File \u001b[0;32m~/anaconda3/envs/StrokePredictionML/lib/python3.10/site-packages/pkg_resources/__init__.py:417\u001b[0m, in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m working_set\u001b[38;5;241m.\u001b[39mfind(moduleOrReq) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mrequire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmoduleOrReq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[moduleOrReq]\n",
      "File \u001b[0;32m~/anaconda3/envs/StrokePredictionML/lib/python3.10/site-packages/pkg_resources/__init__.py:1070\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mrequirements: _NestedStr) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Distribution]:\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1070\u001b[0m     needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m needed:\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(dist)\n",
      "File \u001b[0;32m~/anaconda3/envs/StrokePredictionML/lib/python3.10/site-packages/pkg_resources/__init__.py:897\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m req_extras\u001b[38;5;241m.\u001b[39mmarkers_pass(req, extras):\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_dist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace_conflicting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstaller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_activate\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# push the new requirements onto the stack\u001b[39;00m\n\u001b[1;32m    902\u001b[0m new_requirements \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mrequires(req\u001b[38;5;241m.\u001b[39mextras)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/StrokePredictionML/lib/python3.10/site-packages/pkg_resources/__init__.py:943\u001b[0m, in \u001b[0;36mWorkingSet._resolve_dist\u001b[0;34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m req:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n\u001b[1;32m    942\u001b[0m     dependent_req \u001b[38;5;241m=\u001b[39m required_by[req]\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m VersionConflict(dist, req)\u001b[38;5;241m.\u001b[39mwith_context(dependent_req)\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dist\n",
      "\u001b[0;31mContextualVersionConflict\u001b[0m: (torch 2.5.1 (/home/jarvis/.local/lib/python3.10/site-packages), Requirement.parse('torch<=2.1.0,>=1.13.1'), {'rknn-toolkit2'})"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "builtins.exit = quit  # Manually define `exit`\n",
    "from rknn.api import RKNN\n",
    "\n",
    "ONNX_MODEL_PATH = './Models/best_model_91.onnx'\n",
    "RKNN_MODEL_PATH = './Models/best_model_91.rknn'\n",
    "\n",
    "rknn = RKNN()\n",
    "\n",
    "print('--> Configuring RKNN (FP16)')\n",
    "rknn.config(\n",
    "    mean_values=None,\n",
    "    std_values=None,\n",
    "    target_platform='rk3588',\n",
    "    quantized_dtype='float16'\n",
    ")\n",
    "print('Done.')\n",
    "\n",
    "print('--> Loading ONNX model')\n",
    "ret = rknn.load_onnx(model=ONNX_MODEL_PATH)\n",
    "if ret != 0:\n",
    "    print('❌ Failed to load ONNX model')\n",
    "    exit(ret)\n",
    "print('Done.')\n",
    "\n",
    "print('--> Building RKNN model (FP16 quantization)')\n",
    "ret = rknn.build(do_quantization=True)\n",
    "if ret != 0:\n",
    "    print('❌ Build failed')\n",
    "    exit(ret)\n",
    "print('Done.')\n",
    "\n",
    "print('--> Exporting RKNN model')\n",
    "ret = rknn.export_rknn(RKNN_MODEL_PATH)\n",
    "if ret != 0:\n",
    "    print('❌ Export failed')\n",
    "    exit(ret)\n",
    "print(f'✅ RKNN model saved to {RKNN_MODEL_PATH}')\n",
    "\n",
    "rknn.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271ee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StrokePredictionML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
